{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54b6241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016e8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(stock):\n",
    "    filepath = f\"C:/Users/danie/Documents/Software/Python-Finance-QuantConnect/DATA/{stock}.csv\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(\"len(df): \", len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "134879fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def technical_indicators(df, n_ma, n_future):\n",
    "    \"\"\"\n",
    "    calculate technical indicators of the stock\n",
    "    :returns: updated dataframe\n",
    "    \"\"\"\n",
    "    df['Daily Returns'] = df[\"Adj Close\"].pct_change(1)\n",
    "    df['Log Returns'] = np.log(1 + df['Daily Returns'])\n",
    "    # TODO: drop these two lines (and check)\n",
    "#     df.dropna(inplace=True) \n",
    "#     df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Calculate Exponential Moving Average (EMA)\n",
    "    df['EMA'] = df['Log Returns'].ewm(span=n_ma, adjust=False).mean()\n",
    "    # Calculate the simple moving average (SMA) for a window of n days\n",
    "    df['SMA'] = df['Log Returns'].rolling(window=n_ma).mean()\n",
    "    # SMA used for dependent variable\n",
    "    df['y_SMA'] = df['Log Returns'].rolling(window=n_future).mean()\n",
    "    \n",
    "    # Calculate the short-term EMA (12 periods)\n",
    "    df['EMA_12'] = df['Adj Close'].ewm(span=12, adjust=False).mean()\n",
    "    # Calculate the long-term EMA (26 periods)\n",
    "    df['EMA_26'] = df['Adj Close'].ewm(span=26, adjust=False).mean()\n",
    "    # Calculate the MACD line\n",
    "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "    # Calculate the Signal line\n",
    "    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    # Calculate the rate of change for MACD\n",
    "    df['MACD_Rate_of_Change'] = df['MACD'].pct_change()\n",
    "    df['MACD_Rate_of_Change'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    # You can then fill the NaNs with a suitable value, like 0 or the mean of the column\n",
    "#     df['MACD_Rate_of_Change'].fillna(0, inplace=True)\n",
    "\n",
    "    # If you want to fill with the mean, ensure to calculate the mean without the inf/-inf values\n",
    "    mean_value = df['MACD_Rate_of_Change'].mean()\n",
    "    df['MACD_Rate_of_Change'].fillna(mean_value, inplace=True)\n",
    "\n",
    "    # Encoding the crossover\n",
    "    df['MACD_Crossover_Up'] = (df['MACD'] > df['Signal_Line']).astype(int)\n",
    "    df['MACD_Crossover_Down'] = (df['MACD'] < df['Signal_Line']).astype(int)\n",
    "    \n",
    "    max_value_threshold = 1e9  # example threshold, adjust as necessary\n",
    "    if df['MACD_Rate_of_Change'].abs().max() > max_value_threshold:\n",
    "        print(f\"Values too large found in 'MACD_Rate_of_Change' exceeding {max_value_threshold}\")\n",
    "\n",
    "    df = df.dropna(subset=['Log Returns', 'EMA'])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d94cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "def LR_MACD(df, n_days, n_ma, n_future):  \n",
    "    \n",
    "    df = technical_indicators(df, n_ma, n_future)\n",
    "#     print(\"df.head: \", df.head())\n",
    "#     print(\"df.head: \", df.head())\n",
    "    \n",
    "    # Initialize X and Y\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    # Populate X and Y\n",
    "    for i in range((n_days-1)*n_ma, len(df)-n_future):\n",
    "#     for i in range(n_days*n_ma, n_days*n_ma + 55):\n",
    "        emas = df[['EMA']].iloc[i-(n_days-1)*n_ma:i+1:n_ma].values.flatten()\n",
    "        macd_value = df['MACD'].iloc[i]\n",
    "        signal_line = df['Signal_Line'].iloc[i]\n",
    "        macd_rate_of_change = df['MACD_Rate_of_Change'].iloc[i]\n",
    "        macd_crossover_up = df['MACD_Crossover_Up'].iloc[i]\n",
    "        macd_crossover_down = df['MACD_Crossover_Down'].iloc[i]\n",
    "\n",
    "        features = list(emas) + [macd_value, signal_line, macd_rate_of_change, macd_crossover_up, macd_crossover_down]\n",
    "        X.append(features)\n",
    "\n",
    "        y_SMA = df['y_SMA'].iloc[i+n_future]\n",
    "        Y.append(y_SMA)\n",
    "\n",
    "    # split data\n",
    "    test_size = int(len(X) * 0.2)\n",
    "\n",
    "    # Training set\n",
    "    X_train = X[:-test_size]\n",
    "    y_train = Y[:-test_size]\n",
    "\n",
    "    # Testing set\n",
    "    X_test = X[-test_size:]\n",
    "    y_test = Y[-test_size:]\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    k = n_days + 3  # or any other number you want to keep\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(with_mean=False),\n",
    "        SelectKBest(f_regression, k=k),\n",
    "        LinearRegression()\n",
    "    )\n",
    "#     model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "    model.fit(X_train, y_train)\n",
    "    # normalize = False (input data)\n",
    "    # copy_x = True (overwrite input variables)\n",
    "    # n_jobs = None (number of parallelism. -1 uses all available processors)\n",
    "\n",
    "    r_sq = model.score(X_test, y_test)\n",
    "    \n",
    "    # Assuming your pipeline is named 'model' and it has been fit to your data:\n",
    "    selected_features = model.named_steps['selectkbest'].get_support()\n",
    "    feature_scores = model.named_steps['selectkbest'].scores_\n",
    "\n",
    "    # To get the names of the selected features, if you have them:\n",
    "#     feature_names = np.array(your_feature_names)  # Replace with your actual feature names\n",
    "#     selected_feature_names = feature_names[selected_features]\n",
    "\n",
    "    # Print the selected feature names:\n",
    "#     print(\"Selected features:\", selected_feature_names)\n",
    "\n",
    "    # And if you want to print the scores:\n",
    "#     print(\"Scores for all features:\", feature_scores)\n",
    "\n",
    "    # To print the scores for the selected features:\n",
    "#     print(\"Scores for selected features:\", feature_scores[selected_features])\n",
    "#     print(f\"coefficient of determination: {r_sq}\")\n",
    "#     print(f\"intercept: {model.intercept_}\")\n",
    "#     print(f\"slope: {model.coef_}\")\n",
    "    return r_sq, feature_scores[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953b8344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df):  1258\n",
      "stock_ranges: {'days': (1, 10), 'n_ma': (7, 13), 'n_future': (1, 12, 2)}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1005,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 55>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m#     print(\"best:\\n\", best)\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     print_comparison3(best, secondbest)\n\u001b[1;32m---> 55\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m n_ma \u001b[38;5;129;01min\u001b[39;00m n_mas:\n\u001b[0;32m     29\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m n_future \u001b[38;5;129;01min\u001b[39;00m n_futures:\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#                     print(f\"days: {days}, n_ma: {n_ma}, n_future: {n_future}\")\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m                     r_sq, feature_scores \u001b[38;5;241m=\u001b[39m \u001b[43mLR_MACD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_future\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m                     \u001b[38;5;28;01mif\u001b[39;00m r_sq \u001b[38;5;241m>\u001b[39m best[stock][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_sq\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     33\u001b[0m                         secondbest[stock] \u001b[38;5;241m=\u001b[39m best[stock]\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mLR_MACD\u001b[1;34m(df, n_days, n_ma, n_future)\u001b[0m\n\u001b[0;32m     44\u001b[0m     model \u001b[38;5;241m=\u001b[39m make_pipeline(\n\u001b[0;32m     45\u001b[0m         StandardScaler(with_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     46\u001b[0m         SelectKBest(f_regression, k\u001b[38;5;241m=\u001b[39mk),\n\u001b[0;32m     47\u001b[0m         LinearRegression()\n\u001b[0;32m     48\u001b[0m     )\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m#     model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# normalize = False (input data)\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# copy_x = True (overwrite input variables)\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# n_jobs = None (number of parallelism. -1 uses all available processors)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     r_sq \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    389\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 390\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    346\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 348\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    349\u001b[0m     cloned_transformer,\n\u001b[0;32m    350\u001b[0m     X,\n\u001b[0;32m    351\u001b[0m     y,\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    353\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    354\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    356\u001b[0m )\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:855\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:806\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:841\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    840\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 841\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    849\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1005,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def main():\n",
    "    stocks = ['AAPL','BAC','COST'] #,'C','DG','FB','HSBC','JPM']\n",
    "    best = {}\n",
    "    secondbest = {}\n",
    "\n",
    "    # Start time for the whole calculation\n",
    "    start_time_total = time.time()\n",
    "\n",
    "    for stock in stocks:\n",
    "        # Start time for the current stock calculation\n",
    "        start_time_stock = time.time()\n",
    "\n",
    "        df = read_csv(stock)\n",
    "        best[stock] = {'r_sq': -1e9}\n",
    "        secondbest[stock] = {'r_sq': -1e9}\n",
    "\n",
    "         # Get the ranges for the current stock\n",
    "        stock_ranges = ranges[stock]\n",
    "        print(f\"stock_ranges: {stock_ranges}\")\n",
    "        days_list = list(range(*stock_ranges['days']))\n",
    "        n_mas = list(range(*stock_ranges['n_ma']))\n",
    "        n_futures = list(range(*stock_ranges['n_future']))\n",
    "#         days_list = n_mas = n_futures = [1,5]\n",
    "\n",
    "        for days in days_list:\n",
    "            for n_ma in n_mas:\n",
    "                for n_future in n_futures:\n",
    "#                     print(f\"days: {days}, n_ma: {n_ma}, n_future: {n_future}\")\n",
    "                    r_sq, feature_scores = LR_MACD(df.copy(), days, n_ma, n_future)\n",
    "                    if r_sq > best[stock]['r_sq']:\n",
    "                        secondbest[stock] = best[stock]\n",
    "                        best[stock] = {'r_sq': r_sq, 'days': days, \n",
    "                                       'n_ma': n_ma, 'n_future': n_future, 'feature_scores': feature_scores}\n",
    "                        print(\"new best[stock]: \", best[stock])\n",
    "                    elif r_sq > secondbest[stock]['r_sq']:\n",
    "                        secondbest[stock] = {'r_sq': r_sq, 'days': days, \n",
    "                                             'n_ma': n_ma, 'n_future': n_future, 'feature_scores': feature_scores}\n",
    "                        print(\"new secondbest: \", secondbest[stock])\n",
    "            print(\". \", end=\"\")\n",
    "    #         print(f\"{days} days best: {best[stock]}\")\n",
    "        # End time for the current stock calculation\n",
    "        end_time_stock = time.time()\n",
    "        print(f\"Time for {stock}: {(end_time_stock - start_time_stock)//60:.0f} minutes\"\n",
    "              f\" and {(end_time_stock - start_time_stock)%60:.0f} seconds.\")\n",
    "        print(f\"best[{stock}] is: {best[stock]}\\n\")\n",
    "\n",
    "    end_time_total = time.time()\n",
    "    print(f\"Total time: {(end_time_total - start_time_total)//60:.0f} minutes\"\n",
    "          f\" and {(end_time_total - start_time_total)%60:.0f} seconds\")\n",
    "#     print(\"best:\\n\", best)\n",
    "    print_comparison3(best, secondbest)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "400d600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = {'AAPL': {'days': (1, 10), 'n_ma': (7, 13), 'n_future': (1, 12, 2)},\n",
    "         'BAC': {'days': (1, 5), 'n_ma': (12, 19), 'n_future': (1, 12, 2)},\n",
    "         'COST':  {'days': (8, 15), 'n_ma': (15, 25),'n_future': (1, 12, 2)},\n",
    "         'C':     {'days': (1, 6),  'n_ma': (1, 11), 'n_future': (1, 12, 2)},\n",
    "         'DG':    {'days': (1, 21), 'n_ma': (1, 21), 'n_future': (1, 21)},\n",
    "         'FB':    {'days': (1, 9), 'n_ma': (8, 21), 'n_future': (4, 11)},\n",
    "         'HSBC':  {'days': (1, 21), 'n_ma': (1, 21), 'n_future': (1, 21)},\n",
    "         'JPM':   {'days': (1, 21), 'n_ma': (1, 21), 'n_future': (1, 21)}}\n",
    "\n",
    "# Ticker        R^2                 Days       n_ma       n_future\n",
    "# -----------------------------------------------------------------\n",
    "# AAPL      0.02480 (   0.02455)      6 (  6)     17 ( 17)         8 (        6)\n",
    "# BAC       0.00026 (  -0.00018)      4 (  3)     12 ( 12)         1 (        1)\n",
    "# COST      0.06092 (   0.05711)      9 (  7)     16 ( 16)        10 (       10)\n",
    "# C         0.00722 (   0.00099)      2 (  1)      1 ( 20)         1 (        2)\n",
    "# DG        0.01292 (   0.00944)      7 (  5)      9 ( 18)         2 (        2)\n",
    "# FB        0.06486 (   0.05884)     10 (  6)     10 ( 18)         5 (        8)\n",
    "# HSBC      0.01981 (   0.01823)      7 (  3)      2 (  1)         1 (        1)\n",
    "# JPM       0.00436 (   0.00224)      4 (  3)     12 ( 12)         2 (        2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "4133795c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df):  1258\n",
      "stock_ranges: {'days': (7, 12), 'n_ma': (2, 12), 'n_future': (1, 5)}\n",
      "new best[stock]:  {'r_sq': 0.004367860912637411, 'days': 7, 'n_ma': 2, 'n_future': 1}\n",
      "new best[stock]:  {'r_sq': 0.006212028567458505, 'days': 7, 'n_ma': 3, 'n_future': 3}\n",
      "new best[stock]:  {'r_sq': 0.007486773938031432, 'days': 7, 'n_ma': 6, 'n_future': 1}\n",
      "new best[stock]:  {'r_sq': 0.012391589435892136, 'days': 7, 'n_ma': 7, 'n_future': 1}\n",
      ".new best[stock]:  {'r_sq': 0.017431723477691174, 'days': 8, 'n_ma': 3, 'n_future': 3}\n",
      "..new best[stock]:  {'r_sq': 0.022319693618527814, 'days': 10, 'n_ma': 10, 'n_future': 1}\n",
      ".new best[stock]:  {'r_sq': 0.023623854324563487, 'days': 11, 'n_ma': 10, 'n_future': 1}\n",
      "new best[stock]:  {'r_sq': 0.025996372211829044, 'days': 11, 'n_ma': 10, 'n_future': 3}\n",
      ".Time for AAPL: 2.0 minutes and 15.316807508468628 seconds.\n",
      "best[AAPL] is: {'r_sq': 0.025996372211829044, 'days': 11, 'n_ma': 10, 'n_future': 3}\n",
      "\n",
      "len(df):  1259\n",
      "stock_ranges: {'days': (1, 5), 'n_ma': (1, 6), 'n_future': (1, 3)}\n",
      "new best[stock]:  {'r_sq': -0.013607489144448204, 'days': 1, 'n_ma': 1, 'n_future': 1}\n",
      "new best[stock]:  {'r_sq': -0.01164888064889169, 'days': 1, 'n_ma': 1, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.010126889182242804, 'days': 1, 'n_ma': 2, 'n_future': 1}\n",
      "new best[stock]:  {'r_sq': -0.007325488854952322, 'days': 1, 'n_ma': 3, 'n_future': 1}\n",
      "new best[stock]:  {'r_sq': -0.005791727529017354, 'days': 1, 'n_ma': 4, 'n_future': 1}\n",
      "new best[stock]:  {'r_sq': -0.004835665005295642, 'days': 1, 'n_ma': 5, 'n_future': 1}\n",
      ".new best[stock]:  {'r_sq': -0.004308339855308541, 'days': 2, 'n_ma': 2, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.0026826630279195296, 'days': 2, 'n_ma': 4, 'n_future': 1}\n",
      ".new best[stock]:  {'r_sq': -0.0006788315652583865, 'days': 3, 'n_ma': 2, 'n_future': 1}\n",
      "..Time for BAC: 0.0 minutes and 28.339402437210083 seconds.\n",
      "best[BAC] is: {'r_sq': -0.0006788315652583865, 'days': 3, 'n_ma': 2, 'n_future': 1}\n",
      "\n",
      "len(df):  1258\n",
      "stock_ranges: {'days': (8, 11), 'n_ma': (21, 23), 'n_future': (21, 24)}\n",
      "new best[stock]:  {'r_sq': 0.14577481530701064, 'days': 8, 'n_ma': 21, 'n_future': 21}\n",
      "new best[stock]:  {'r_sq': 0.15227295802284646, 'days': 8, 'n_ma': 21, 'n_future': 22}\n",
      ".new best[stock]:  {'r_sq': 0.17625814044533783, 'days': 9, 'n_ma': 21, 'n_future': 21}\n",
      "new best[stock]:  {'r_sq': 0.18192839058993204, 'days': 9, 'n_ma': 21, 'n_future': 22}\n",
      "..Time for COST: 0.0 minutes and 10.915651321411133 seconds.\n",
      "best[COST] is: {'r_sq': 0.18192839058993204, 'days': 9, 'n_ma': 21, 'n_future': 22}\n",
      "\n",
      "len(df):  1259\n",
      "stock_ranges: {'days': (1, 4), 'n_ma': (1, 12), 'n_future': (1, 4)}\n",
      "new best[stock]:  {'r_sq': -0.007889754761806644, 'days': 1, 'n_ma': 1, 'n_future': 1}\n",
      "new best[stock]:  {'r_sq': -0.006984640696524158, 'days': 1, 'n_ma': 2, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.005795444695989138, 'days': 1, 'n_ma': 3, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.005149646649003303, 'days': 1, 'n_ma': 4, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.004504565368393054, 'days': 1, 'n_ma': 5, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.0037827353752613035, 'days': 1, 'n_ma': 6, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.003053214672200655, 'days': 1, 'n_ma': 7, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.0023885842799260537, 'days': 1, 'n_ma': 8, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.001829863059685355, 'days': 1, 'n_ma': 9, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.0013903096529659376, 'days': 1, 'n_ma': 10, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.0010664139584766197, 'days': 1, 'n_ma': 11, 'n_future': 2}\n",
      ".new best[stock]:  {'r_sq': 0.007217831487729143, 'days': 2, 'n_ma': 1, 'n_future': 1}\n",
      "..Time for C: 1.0 minutes and 11.272286415100098 seconds.\n",
      "best[C] is: {'r_sq': 0.007217831487729143, 'days': 2, 'n_ma': 1, 'n_future': 1}\n",
      "\n",
      "len(df):  1258\n",
      "stock_ranges: {'days': (4, 9), 'n_ma': (8, 20), 'n_future': (1, 4)}\n",
      "new best[stock]:  {'r_sq': -0.01199629334068364, 'days': 4, 'n_ma': 8, 'n_future': 1}\n",
      "new best[stock]:  {'r_sq': -0.011454261729582305, 'days': 4, 'n_ma': 8, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.010536159951928914, 'days': 4, 'n_ma': 8, 'n_future': 3}\n",
      "new best[stock]:  {'r_sq': -0.0008609175002152192, 'days': 4, 'n_ma': 9, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': 0.003845417282144714, 'days': 4, 'n_ma': 18, 'n_future': 2}\n",
      ".new best[stock]:  {'r_sq': 0.005393315914897001, 'days': 5, 'n_ma': 18, 'n_future': 2}\n",
      "..new best[stock]:  {'r_sq': 0.008895093752942618, 'days': 7, 'n_ma': 9, 'n_future': 2}\n",
      "..Time for DG: 2.0 minutes and 1.0260932445526123 seconds.\n",
      "best[DG] is: {'r_sq': 0.008895093752942618, 'days': 7, 'n_ma': 9, 'n_future': 2}\n",
      "\n",
      "len(df):  1258\n",
      "stock_ranges: {'days': (1, 3), 'n_ma': (7, 10), 'n_future': (5, 10)}\n",
      "new best[stock]:  {'r_sq': 0.028546473553611507, 'days': 1, 'n_ma': 7, 'n_future': 5}\n",
      "new best[stock]:  {'r_sq': 0.0364406629756886, 'days': 1, 'n_ma': 7, 'n_future': 6}\n",
      "new best[stock]:  {'r_sq': 0.0454141404059073, 'days': 1, 'n_ma': 7, 'n_future': 8}\n",
      "..Time for FB: 0.0 minutes and 21.085281133651733 seconds.\n",
      "best[FB] is: {'r_sq': 0.0454141404059073, 'days': 1, 'n_ma': 7, 'n_future': 8}\n",
      "\n",
      "len(df):  1259\n",
      "stock_ranges: {'days': (1, 5), 'n_ma': (1, 3), 'n_future': (1, 3)}\n",
      "new best[stock]:  {'r_sq': 0.007475176134334349, 'days': 1, 'n_ma': 1, 'n_future': 1}\n",
      ".new best[stock]:  {'r_sq': 0.012490410014206477, 'days': 2, 'n_ma': 1, 'n_future': 1}\n",
      ".new best[stock]:  {'r_sq': 0.01823042043719425, 'days': 3, 'n_ma': 1, 'n_future': 1}\n",
      "..Time for HSBC: 0.0 minutes and 11.561472654342651 seconds.\n",
      "best[HSBC] is: {'r_sq': 0.01823042043719425, 'days': 3, 'n_ma': 1, 'n_future': 1}\n",
      "\n",
      "len(df):  1259\n",
      "stock_ranges: {'days': (2, 6), 'n_ma': (11, 14), 'n_future': (1, 4)}\n",
      "new best[stock]:  {'r_sq': -0.009520227877539256, 'days': 2, 'n_ma': 11, 'n_future': 1}\n",
      ".new best[stock]:  {'r_sq': -0.007579051934045511, 'days': 3, 'n_ma': 11, 'n_future': 2}\n",
      "new best[stock]:  {'r_sq': -0.0032843999761924536, 'days': 3, 'n_ma': 12, 'n_future': 1}\n",
      ".new best[stock]:  {'r_sq': 0.0016887753348129309, 'days': 4, 'n_ma': 12, 'n_future': 2}\n",
      "..Time for JPM: 0.0 minutes and 25.02304482460022 seconds.\n",
      "best[JPM] is: {'r_sq': 0.0016887753348129309, 'days': 4, 'n_ma': 12, 'n_future': 2}\n",
      "\n",
      "Total time: 424.54 seconds\n",
      "Ticker        R^2                 Days        n_ma      n_future\n",
      "----------------------------------------------------------------\n",
      "AAPL      0.02600 (   0.02362)     11 ( 11)     10 ( 10)      3 (  1)\n",
      "BAC      -0.00068 (  -0.00268)      3 (  2)      2 (  4)      1 (  1)\n",
      "COST      0.18193 (   0.17626)      9 (  9)     21 ( 21)     22 ( 21)\n",
      "C         0.00722 (  -0.00107)      2 (  1)      1 ( 11)      1 (  2)\n",
      "DG        0.00890 (   0.00539)      7 (  5)      9 ( 18)      2 (  2)\n",
      "FB        0.04541 (   0.03644)      1 (  1)      7 (  7)      8 (  6)\n",
      "HSBC      0.01823 (   0.01249)      3 (  2)      1 (  1)      1 (  1)\n",
      "JPM       0.00169 (  -0.00328)      4 (  3)     12 ( 12)      2 (  1)\n",
      "\n",
      "Performance Summary:\n",
      "Metric        R^2                Days                n_ma               n_fut\n",
      "Average   0.03609 ( 0.03090)  5.00 ( 4.25)  7.88 (10.50)  5.00 ( 4.38)\n",
      "Median    0.01356 ( 0.00894)  3.50 ( 2.50)  8.00 (10.50)  2.00 ( 1.50)\n",
      "StDev     0.06081 ( 0.06038)  3.59 ( 3.81)  6.81 ( 6.70)  7.25 ( 6.93)\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "if __name__ == \"__main__\":\n",
    "    cProfile.run('main()', 'profiling_results.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618aeef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats\n",
    "\n",
    "# Create a Stats object\n",
    "p = pstats.Stats('profiling_results.out')\n",
    "\n",
    "# Print the statistics\n",
    "# p.strip_dirs().sort_stats(-1).print_stats()\n",
    "p.sort_stats('cumulative').print_stats(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "43b24ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = {\n",
    "    'AAPL': {'days': (7, 12), 'n_ma': (7, 12), 'n_future': (1, 5)},\n",
    "    'BAC': {'days': (1, 11), 'n_ma': (1, 15), 'n_future': (1, 11)},\n",
    "    'COST': {'days': (8, 11), 'n_ma': (21, 23), 'n_future': (21, 24)},\n",
    "    'C': {'days': (1, 4), 'n_ma': (1, 12), 'n_future': (1, 4)},\n",
    "    'DG': {'days': (4, 9), 'n_ma': (8, 20), 'n_future': (1, 4)},\n",
    "    'FB': {'days': (1, 3), 'n_ma': (7, 10), 'n_future': (5, 10)},\n",
    "    'HSBC': {'days': (1, 5), 'n_ma': (1, 3), 'n_future': (1, 3)},\n",
    "    'JPM': {'days': (2, 6), 'n_ma': (11, 14), 'n_future': (1, 4)}\n",
    "}\n",
    "# Ticker        R^2                 Days        n_ma      n_future\n",
    "# ----------------------------------------------------------------\n",
    "# AAPL      0.02232 (   0.01743)     10 (  8)     10 (  3)      1 (  3)\n",
    "# BAC      -0.00068 (  -0.00268)      3 (  2)      2 (  4)      1 (  1)\n",
    "# COST      0.18193 (   0.17626)      9 (  9)     21 ( 21)     22 ( 21)\n",
    "# C         0.00722 (  -0.00139)      2 (  1)      1 ( 10)      1 (  2)\n",
    "# DG        0.00890 (   0.00539)      7 (  5)      9 ( 18)      2 (  2)\n",
    "# FB        0.04299 (   0.03557)      1 (  1)      8 (  8)      8 (  6)\n",
    "# HSBC      0.01823 (   0.01249)      3 (  2)      1 (  1)      1 (  1)\n",
    "# JPM       0.00169 (  -0.00328)      4 (  3)     12 ( 12)      2 (  1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "110265d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import math\n",
    "\n",
    "def print_comparison3(best, secondbest):\n",
    "    # Print the header\n",
    "    header = f\"{'Ticker':<6} {'R^2':>10} {'':>13} {'Days':>6} {'':>4} {'n_ma':>6} {'':>4} {'n_future':>6}\"\n",
    "    print(header)\n",
    "    print('-' * len(header))\n",
    "\n",
    "    # Initialize lists to hold the values for calculating the summary statistics\n",
    "    r2_values = []\n",
    "    r2_values_second = []\n",
    "    days_values = []\n",
    "    days_values_second = []\n",
    "    n_ma_values = []\n",
    "    n_ma_values_second = []\n",
    "    n_future_values = []\n",
    "    n_future_values_second = []\n",
    "\n",
    "    # Print each item and collect values for the summary\n",
    "    for ticker in best:\n",
    "        best_metrics = best[ticker]\n",
    "        secondbest_metrics = secondbest.get(ticker, {})\n",
    "        \n",
    "        # Append values for best and second best performance\n",
    "        r2_values.append(best_metrics['r_sq'])\n",
    "        r2_values_second.append(secondbest_metrics.get('r_sq', float('nan')))\n",
    "        days_values.append(best_metrics['days'])\n",
    "        days_values_second.append(secondbest_metrics.get('days', float('nan')))\n",
    "        n_ma_values.append(best_metrics['n_ma'])\n",
    "        n_ma_values_second.append(secondbest_metrics.get('n_ma', float('nan')))\n",
    "        n_future_values.append(best_metrics['n_future'])\n",
    "        n_future_values_second.append(secondbest_metrics.get('n_future', float('nan')))\n",
    "        \n",
    "        # Format and print the line for each ticker\n",
    "        line = f\"{ticker:<6} {best_metrics['r_sq']:>10.5f} ({secondbest_metrics.get('r_sq', 'n/a'):>10.5f}) \"\n",
    "        line += f\"{best_metrics['days']:>6} ({secondbest_metrics.get('days', 'n/a'):>3}) \"\n",
    "        line += f\"{best_metrics['n_ma']:>6} ({secondbest_metrics.get('n_ma', 'n/a'):>3})\"\n",
    "        line += f\" {best_metrics['n_future']:>6} ({secondbest_metrics.get('n_future', 'n/a'):>3})\"\n",
    "        print(line)\n",
    "\n",
    "    # Calculate the summary statistics for best and second best performances\n",
    "    def calculate_summary(values):\n",
    "        # Filter out nan values for accurate calculation\n",
    "        filtered_values = [v for v in values if not math.isnan(v)]\n",
    "        average = statistics.mean(filtered_values)\n",
    "        median = statistics.median(filtered_values)\n",
    "        stdev = statistics.stdev(filtered_values) if len(filtered_values) > 1 else 0\n",
    "        return average, median, stdev\n",
    "\n",
    "    # Calculate and print the best performance summary\n",
    "    r2_avg, r2_med, r2_stdev = calculate_summary(r2_values)\n",
    "    days_avg, days_med, days_stdev = calculate_summary(days_values)\n",
    "    n_ma_avg, n_ma_med, n_ma_stdev = calculate_summary(n_ma_values)\n",
    "    n_future_avg, n_future_med, n_future_stdev = calculate_summary(n_future_values)\n",
    "    \n",
    "    # Calculate and print the second best performance summary\n",
    "    r2_avg_second, r2_med_second, r2_stdev_second = calculate_summary(r2_values_second)\n",
    "    days_avg_second, days_med_second, days_stdev_second = calculate_summary(days_values_second)\n",
    "    n_ma_avg_second, n_ma_med_second, n_ma_stdev_second = calculate_summary(n_ma_values_second)\n",
    "    n_future_avg_second, n_future_med_second, n_future_stdev_second = calculate_summary(n_future_values_second)\n",
    "\n",
    "\n",
    "    # Print the rows for Average, Median, and StDev with the calculated values\n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    print(f\"{'Metric':<8} {'R^2':>8.5} {'':>10} {'Days':>8.5} {'':>10} {'n_ma':>8.5} {'':>10} {'n_future':>8.5}\")\n",
    "    # Print the rows for Average, Median, and StDev with the best and second-best values\n",
    "    print(f\"{'Average':<8} {r2_avg:>8.5f} ({r2_avg_second:>8.5f}) {days_avg:>5.2f} ({days_avg_second:>5.2f}) {n_ma_avg:>5.2f} ({n_ma_avg_second:>5.2f}) {n_future_avg:>5.2f} ({n_future_avg_second:>5.2f})\")\n",
    "    print(f\"{'Median':<8} {r2_med:>8.5f} ({r2_med_second:>8.5f}) {days_med:>5.2f} ({days_med_second:>5.2f}) {n_ma_med:>5.2f} ({n_ma_med_second:>5.2f}) {n_future_med:>5.2f} ({n_future_med_second:>5.2f})\")\n",
    "    print(f\"{'StDev':<8} {r2_stdev:>8.5f} ({r2_stdev_second:>8.5f}) {days_stdev:>5.2f} ({days_stdev_second:>5.2f}) {n_ma_stdev:>5.2f} ({n_ma_stdev_second:>5.2f}) {n_future_stdev:>5.2f} ({n_future_stdev_second:>5.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b6d324bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_runs(df, n_days):    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    # Initialize X and Y\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    # Populate X and Y\n",
    "    # n = max(n_days, n_sma)\n",
    "#     print(df[['Adj Close','SMA']].head())\n",
    "#     for i in range(n_days*n_sma, n_days*n_sma+5):\n",
    "    for i in range(n_days, len(df)):\n",
    "        #print(\"i: \", i)\n",
    "        X.append(df[['Log Returns']].iloc[i-n_days:i].values.flatten())\n",
    "        Y.append(df['Log Returns'].iloc[i])\n",
    "#     print(f\"len(X)= {len(X)}, X[{i}]: {X}\")\n",
    "#     print(f\"len(Y)= {len(Y)}, Y[{i}]: {Y}\")\n",
    "#     print()\n",
    "#     print(df['SMA'].head(10))\n",
    "\n",
    "    # split data\n",
    "    test_size = int(len(X) * 0.2)\n",
    "\n",
    "    # Training set\n",
    "    X_train = X[:-test_size]\n",
    "    y_train = Y[:-test_size]\n",
    "\n",
    "    # Testing set\n",
    "    X_test = X[-test_size:]\n",
    "    y_test = Y[-test_size:]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    # normalize = False (input data)\n",
    "    # copy_x = True (overwrite input variables)\n",
    "    # n_jobs = None (number of parallelism. -1 uses all available processors)\n",
    "\n",
    "    r_sq = model.score(X_test, y_test)\n",
    "    print(f\"coefficient of determination: {r_sq}\")\n",
    "    print(f\"intercept: {model.intercept_}\")\n",
    "    print(f\"slope: {model.coef_}\")\n",
    "    return r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebbab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_EMA(df, n_days, n_ema):    \n",
    "    # Calculate Exponential Moving Average (EMA)\n",
    "    df['EMA'] = df['Log Returns'].ewm(span=n_ema, adjust=False).mean()\n",
    "\n",
    "    df = df.dropna(subset=['Log Returns', 'EMA'])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Initialize X and Y\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    # Populate X and Y\n",
    "    for i in range(n_days*n_ema, len(df)):\n",
    "        #print(\"i: \", i)\n",
    "        X.append(df[['EMA']].iloc[i-n_days*n_ema:i:n_ema].values.flatten())\n",
    "        Y.append(df['EMA'].iloc[i])\n",
    "\n",
    "    # split data\n",
    "    test_size = int(len(X) * 0.2)\n",
    "\n",
    "    # Training set\n",
    "    X_train = X[:-test_size]\n",
    "    y_train = Y[:-test_size]\n",
    "\n",
    "    # Testing set\n",
    "    X_test = X[-test_size:]\n",
    "    y_test = Y[-test_size:]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model = LinearRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "    # normalize = False (input data)\n",
    "    # copy_x = True (overwrite input variables)\n",
    "    # n_jobs = None (number of parallelism. -1 uses all available processors)\n",
    "\n",
    "    r_sq = model.score(X_test, y_test)\n",
    "#     print(f\"coefficient of determination: {r_sq}\")\n",
    "#     print(f\"intercept: {model.intercept_}\")\n",
    "#     print(f\"slope: {model.coef_}\")\n",
    "    return r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "377e8548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_SMA(df, n_days, n_sma):    \n",
    "    # Calculate the simple moving average (SMA) for a window of n days\n",
    "    df['SMA'] = df['Log Returns'].rolling(window=n_sma).mean()\n",
    "\n",
    "    df = df.dropna(subset=['Log Returns', 'SMA'])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Initialize X and Y\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    # Populate X and Y\n",
    "    for i in range(n_days*n_sma, len(df)):\n",
    "        #print(\"i: \", i)\n",
    "        X.append(df[['SMA']].iloc[i-n_days*n_sma:i:n_sma].values.flatten())\n",
    "#         X.append(df[['SMA']].iloc[i-n_days*n_sma:i:n_sma].values.flatten())\n",
    "        Y.append(df['SMA'].iloc[i])\n",
    "\n",
    "    # split data\n",
    "    test_size = int(len(X) * 0.2)\n",
    "\n",
    "    # Training set\n",
    "    X_train = X[:-test_size]\n",
    "    y_train = Y[:-test_size]\n",
    "\n",
    "    # Testing set\n",
    "    X_test = X[-test_size:]\n",
    "    y_test = Y[-test_size:]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model = LinearRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "    # normalize = False (input data)\n",
    "    # copy_x = True (overwrite input variables)\n",
    "    # n_jobs = None (number of parallelism. -1 uses all available processors)\n",
    "\n",
    "    r_sq = model.score(X_test, y_test)\n",
    "#     print(f\"coefficient of determination: {r_sq}\")\n",
    "#     print(f\"intercept: {model.intercept_}\")\n",
    "#     print(f\"slope: {model.coef_}\")\n",
    "    return r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9b46175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_tomorrow(df, n_days, n_ma, n_future):  \n",
    "    \n",
    "    df_tech = technical_indicators(df, n_ma, n_future)\n",
    "    \n",
    "    # Initialize X and Y\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    # Populate X and Y\n",
    "    for i in range(n_days*n_ma, len(df_tech)-(-n_ma+1+n_future)):\n",
    "#     for i in range(n_days*n_ma, n_days*n_ma + 45):\n",
    "        emas = df_tech[['EMA']].iloc[i-n_days*n_ma:i:n_ma].values.flatten()\n",
    "        X.append(emas)\n",
    "        y_SMA = df['y_SMA'].iloc[i - n_ma + n_future]\n",
    "        Y.append(y_SMA)\n",
    "\n",
    "    # split data\n",
    "    test_size = int(len(X) * 0.2)\n",
    "\n",
    "    # Training set\n",
    "    X_train = X[:-test_size]\n",
    "    y_train = Y[:-test_size]\n",
    "\n",
    "    # Testing set\n",
    "    X_test = X[-test_size:]\n",
    "    y_test = Y[-test_size:]\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model = LinearRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "    # normalize = False (input data)\n",
    "    # copy_x = True (overwrite input variables)\n",
    "    # n_jobs = None (number of parallelism. -1 uses all available processors)\n",
    "\n",
    "    r_sq = model.score(X_test, y_test)\n",
    "#     print(f\"coefficient of determination: {r_sq}\")\n",
    "#     print(f\"intercept: {model.intercept_}\")\n",
    "#     print(f\"slope: {model.coef_}\")\n",
    "    return r_sq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
